{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Yayerad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download VADER lexicon for sentiment analysis\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing stock data\n",
    "dataAAPL = pd.read_csv('../data/yfinance_data/AAPL_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataMSFT = pd.read_csv('../data/yfinance_data/MSFT_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataGOOGL = pd.read_csv('../data/yfinance_data/GOOG_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Load the existing news data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv', parse_dates=['date'])\n",
    "\n",
    "# Convert to datetime and adjust to UTC\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], utc=True, format='mixed')\n",
    "dataAAPL.index = pd.to_datetime(dataAAPL.index, utc=True)\n",
    "dataMSFT.index = pd.to_datetime(dataMSFT.index, utc=True)\n",
    "dataGOOGL.index = pd.to_datetime(dataGOOGL.index, utc=True)\n",
    "\n",
    "# Extract just the date part\n",
    "news_data['date'] = news_data['date'].dt.date\n",
    "dataAAPL = dataAAPL.reset_index()\n",
    "dataMSFT = dataMSFT.reset_index()\n",
    "dataGOOGL = dataGOOGL.reset_index()\n",
    "\n",
    "dataAAPL['Date'] = dataAAPL['Date'].dt.date\n",
    "dataMSFT['Date'] = dataMSFT['Date'].dt.date\n",
    "dataGOOGL['Date'] = dataGOOGL['Date'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily percentage changes\n",
    "dataAAPL['Daily_Return'] = dataAAPL['Close'].pct_change() * 100  # Multiply by 100 to get percentage\n",
    "dataMSFT['Daily_Return'] = dataMSFT['Close'].pct_change() * 100  # Multiply by 100 to get percentage\n",
    "dataGOOGL['Daily_Return'] = dataGOOGL['Close'].pct_change() * 100  # Multiply by 100 to get percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Sample for AAPL:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "         date stock        Date       Open       High        Low      Close  \\\n",
      "0  2020-06-05     A  2020-06-05  80.837502  82.937500  80.807503  82.875000   \n",
      "1  2020-06-03     A  2020-06-03  81.165001  81.550003  80.574997  81.279999   \n",
      "2  2020-05-26     A  2020-05-26  80.875000  81.059998  79.125000  79.182503   \n",
      "3  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "4  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "\n",
      "   Adj Close       Volume  Dividends  Stock Splits  Daily_Return  \n",
      "0  80.843407  137250400.0        0.0           0.0      2.848099  \n",
      "1  79.287506  104491200.0        0.0           0.0      0.550504  \n",
      "2  77.241432  125522000.0        0.0           0.0     -0.677351  \n",
      "3  77.768188   81803200.0        0.0           0.0      0.643840  \n",
      "4  77.768188   81803200.0        0.0           0.0      0.643840  \n"
     ]
    }
   ],
   "source": [
    "# Merge on the date\n",
    "merged_data_AAPL = pd.merge(news_data, dataAAPL, left_on='date', right_on='Date', how='left')\n",
    "merged_data_MSFT = pd.merge(news_data, dataMSFT, left_on='date', right_on='Date', how='left')\n",
    "merged_data_GOOGL = pd.merge(news_data, dataGOOGL, left_on='date', right_on='Date', how='left')\n",
    "\n",
    "# Handle non-trading days by filling missing stock data with the closest trading day\n",
    "merged_data_AAPL = merged_data_AAPL.ffill()  # Forward fill\n",
    "merged_data_MSFT = merged_data_MSFT.ffill()  # Forward fill\n",
    "merged_data_GOOGL = merged_data_GOOGL.ffill()  # Forward fill\n",
    "\n",
    "print(\"Merged Data Sample for AAPL:\")\n",
    "print(merged_data_AAPL.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data with Sentiment Scores for AAPL:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "         date stock        Date       Open       High        Low      Close  \\\n",
      "0  2020-06-05     A  2020-06-05  80.837502  82.937500  80.807503  82.875000   \n",
      "1  2020-06-03     A  2020-06-03  81.165001  81.550003  80.574997  81.279999   \n",
      "2  2020-05-26     A  2020-05-26  80.875000  81.059998  79.125000  79.182503   \n",
      "3  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "4  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "\n",
      "   Adj Close       Volume  Dividends  Stock Splits  Daily_Return  \\\n",
      "0  80.843407  137250400.0        0.0           0.0      2.848099   \n",
      "1  79.287506  104491200.0        0.0           0.0      0.550504   \n",
      "2  77.241432  125522000.0        0.0           0.0     -0.677351   \n",
      "3  77.768188   81803200.0        0.0           0.0      0.643840   \n",
      "4  77.768188   81803200.0        0.0           0.0      0.643840   \n",
      "\n",
      "   sentiment_score  \n",
      "0            0.000  \n",
      "1            0.000  \n",
      "2            0.000  \n",
      "3            0.000  \n",
      "4            0.296  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Perform sentiment analysis on headlines\n",
    "def get_sentiment_score(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']  # Compound score\n",
    "\n",
    "# Apply sentiment analysis\n",
    "merged_data_AAPL['sentiment_score'] = merged_data_AAPL['headline'].apply(get_sentiment_score)\n",
    "merged_data_MSFT['sentiment_score'] = merged_data_MSFT['headline'].apply(get_sentiment_score)\n",
    "merged_data_GOOGL['sentiment_score'] = merged_data_GOOGL['headline'].apply(get_sentiment_score)\n",
    "\n",
    "# Display the merged DataFrame with sentiment scores\n",
    "print(\"Merged Data with Sentiment Scores for AAPL:\")\n",
    "print(merged_data_AAPL.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Sentiments for AAPL:\n",
      "         date  sentiment_score\n",
      "0  2009-02-14          0.22630\n",
      "1  2009-04-27          0.00000\n",
      "2  2009-04-29          0.00000\n",
      "3  2009-05-22          0.00000\n",
      "4  2009-05-27          0.75105\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentiment scores by date (compute the average)\n",
    "daily_sentiments_AAPL = merged_data_AAPL.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "daily_sentiments_MSFT = merged_data_MSFT.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "daily_sentiments_GOOGL = merged_data_GOOGL.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "\n",
    "# Display the daily sentiment scores\n",
    "print(\"Daily Sentiments for AAPL:\")\n",
    "print(daily_sentiments_AAPL.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data with Aggregated Sentiments and Daily Returns for AAPL:\n",
      "         date  sentiment_score  Daily_Return\n",
      "0  2009-02-14          0.22630           NaN\n",
      "1  2009-04-27          0.00000      0.669889\n",
      "2  2009-04-29          0.00000      1.000808\n",
      "3  2009-05-22          0.00000     -1.352874\n",
      "4  2009-05-27          0.75105      1.735759\n"
     ]
    }
   ],
   "source": [
    "# Ensure stock data contains 'Date' and 'Daily_Return' columns\n",
    "dataAAPL = dataAAPL.rename(columns={'Date': 'date'})\n",
    "dataMSFT = dataMSFT.rename(columns={'Date': 'date'})\n",
    "dataGOOGL = dataGOOGL.rename(columns={'Date': 'date'})\n",
    "\n",
    "dataAAPL = dataAAPL[['date', 'Daily_Return']]  # Ensure only relevant columns are included\n",
    "dataMSFT = dataMSFT[['date', 'Daily_Return']]\n",
    "dataGOOGL = dataGOOGL[['date', 'Daily_Return']]\n",
    "\n",
    "# Merge aggregated sentiment scores with stock data\n",
    "merged_data_AAPL = pd.merge(daily_sentiments_AAPL, dataAAPL, on='date', how='left')\n",
    "merged_data_MSFT = pd.merge(daily_sentiments_MSFT, dataMSFT, on='date', how='left')\n",
    "merged_data_GOOGL = pd.merge(daily_sentiments_GOOGL, dataGOOGL, on='date', how='left')\n",
    "\n",
    "# Display results\n",
    "print(\"Merged Data with Aggregated Sentiments and Daily Returns for AAPL:\")\n",
    "print(merged_data_AAPL.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Sentiment Scores and Daily Returns for AAPL: 0.15\n",
      "Correlation between Sentiment Scores and Daily Returns for MSFT: 0.12\n",
      "Correlation between Sentiment Scores and Daily Returns for GOOGL: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Compute correlation between sentiment scores and daily returns\n",
    "correlation_AAPL = merged_data_AAPL[['sentiment_score', 'Daily_Return']].corr().iloc[0, 1]\n",
    "correlation_MSFT = merged_data_MSFT[['sentiment_score', 'Daily_Return']].corr().iloc[0, 1]\n",
    "correlation_GOOGL = merged_data_GOOGL[['sentiment_score', 'Daily_Return']].corr().iloc[0, 1]\n",
    "\n",
    "# Display the correlation results\n",
    "print(f\"Correlation between Sentiment Scores and Daily Returns for AAPL: {correlation_AAPL:.2f}\")\n",
    "print(f\"Correlation between Sentiment Scores and Daily Returns for MSFT: {correlation_MSFT:.2f}\")\n",
    "print(f\"Correlation between Sentiment Scores and Daily Returns for GOOGL: {correlation_GOOGL:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
